{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78bc71f7",
   "metadata": {},
   "source": [
    "# Web Scraping Assignment-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7cf353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException,TimeoutException,StaleElementReferenceException,ElementClickInterceptedException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c119d7",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia. \n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos \n",
    "\n",
    "You need to find following details:   \n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83dc8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open chrome and load wikipedia webpage\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "48150db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video_name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Baby Shark Dance]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>14.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[Despacito]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[Johny Johny Yes Papa]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[Bath Song]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[Shape of You]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[See You Again]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>[Wheels on the Bus]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>6.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>[Phonics Song with Two Words]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>[Uptown Funk]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>[Gangnam Style]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>[Learning Colors – Colorful Eggs on a Farm]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>[Dame Tu Cosita]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>[Masha and the Bear – Recipe for Disaster]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>[Axel F]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>[Sugar]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>[Baa Baa Black Sheep]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>[Counting Stars]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>[Lakdi Ki Kathi]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>[Roar]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>[Waka Waka (This Time for Africa)]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>[Sorry]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>[Shree Hanuman Chalisa]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>May 10, 2011</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>[Humpty the train on a fruits ride]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>[Thinking Out Loud]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>[Perfect]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>[Dark Horse]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>[Let Her Go]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>[Faded]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>[Girls Like You]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>[Lean On]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                   Video_name  \\\n",
       "0      1                           [Baby Shark Dance]   \n",
       "1      2                                  [Despacito]   \n",
       "2      3                       [Johny Johny Yes Papa]   \n",
       "3      4                                  [Bath Song]   \n",
       "4      5                               [Shape of You]   \n",
       "5      6                              [See You Again]   \n",
       "6      7                          [Wheels on the Bus]   \n",
       "7      8                [Phonics Song with Two Words]   \n",
       "8      9                                [Uptown Funk]   \n",
       "9     10                              [Gangnam Style]   \n",
       "10    11  [Learning Colors – Colorful Eggs on a Farm]   \n",
       "11    12                             [Dame Tu Cosita]   \n",
       "12    13   [Masha and the Bear – Recipe for Disaster]   \n",
       "13    14                                     [Axel F]   \n",
       "14    15                                      [Sugar]   \n",
       "15    16                        [Baa Baa Black Sheep]   \n",
       "16    17                             [Counting Stars]   \n",
       "17    18                             [Lakdi Ki Kathi]   \n",
       "18    19                                       [Roar]   \n",
       "19    20           [Waka Waka (This Time for Africa)]   \n",
       "20    21                                      [Sorry]   \n",
       "21    22                      [Shree Hanuman Chalisa]   \n",
       "22    23          [Humpty the train on a fruits ride]   \n",
       "23    24                          [Thinking Out Loud]   \n",
       "24    25                                    [Perfect]   \n",
       "25    26                                 [Dark Horse]   \n",
       "26    27                                 [Let Her Go]   \n",
       "27    28                                      [Faded]   \n",
       "28    29                             [Girls Like You]   \n",
       "29    30                                    [Lean On]   \n",
       "\n",
       "                                               Artist        Upload_date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                          Ed Sheeran   January 30, 2017   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                                 Psy      July 15, 2012   \n",
       "10                                        Miroshka TV  February 27, 2018   \n",
       "11                                      Ultra Records      April 5, 2018   \n",
       "12                                         Get Movies   January 31, 2012   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                                           Maroon 5   January 14, 2015   \n",
       "15                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "16                                        OneRepublic       May 31, 2013   \n",
       "17                                       Jingle Toons      June 14, 2018   \n",
       "18                                         Katy Perry  September 5, 2013   \n",
       "19                                            Shakira       June 4, 2010   \n",
       "20                                      Justin Bieber   October 22, 2015   \n",
       "21                              T-Series Bhakti Sagar       May 10, 2011   \n",
       "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "23                                         Ed Sheeran    October 7, 2014   \n",
       "24                                         Ed Sheeran   November 9, 2017   \n",
       "25                                         Katy Perry  February 20, 2014   \n",
       "26                                          Passenger      July 25, 2012   \n",
       "27                                        Alan Walker   December 3, 2015   \n",
       "28                                           Maroon 5       May 31, 2018   \n",
       "29                               Major Lazer Official     March 22, 2015   \n",
       "\n",
       "    Views  \n",
       "0   14.32  \n",
       "1    8.41  \n",
       "2    6.89  \n",
       "3    6.66  \n",
       "4    6.23  \n",
       "5    6.22  \n",
       "6    6.01  \n",
       "7    5.75  \n",
       "8    5.18  \n",
       "9    5.10  \n",
       "10   5.09  \n",
       "11   4.59  \n",
       "12   4.57  \n",
       "13   4.45  \n",
       "14   4.02  \n",
       "15   4.01  \n",
       "16   4.00  \n",
       "17   3.98  \n",
       "18   3.98  \n",
       "19   3.89  \n",
       "20   3.78  \n",
       "21   3.77  \n",
       "22   3.76  \n",
       "23   3.75  \n",
       "24   3.70  \n",
       "25   3.70  \n",
       "26   3.64  \n",
       "27   3.60  \n",
       "28   3.58  \n",
       "29   3.57  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scrape the table from webpage\n",
    "\n",
    "try:\n",
    "    table=driver.find_element(By.XPATH,'//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]')\n",
    "\n",
    "    data={'Rank':[],'Video_name':[],'Artist':[],'Upload_date':[],'Views':[]}\n",
    "    rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "\n",
    "    rank=0\n",
    "    for row in rows:\n",
    "        records=row.find_elements(By.TAG_NAME,'td')\n",
    "\n",
    "        vid=[]\n",
    "        art=[]\n",
    "        date=[]\n",
    "        view=[]\n",
    "\n",
    "        for index, record in enumerate(records):\n",
    "\n",
    "            if index==0:\n",
    "                text=record.text\n",
    "                extracted_text=re.findall(r'\"([^\"]+)\"', text)\n",
    "                vid.append(extracted_text)\n",
    "            elif index==1:\n",
    "                art.append(record.text)\n",
    "            elif index==2:\n",
    "                view.append(record.text)\n",
    "            elif index==3:\n",
    "                date.append(record.text)\n",
    "\n",
    "        data['Rank'].extend([rank] * len(vid))\n",
    "        data['Video_name'].extend(vid)\n",
    "        data['Artist'].extend(art)\n",
    "        data['Upload_date'].extend(date)\n",
    "        data['Views'].extend(view)\n",
    "\n",
    "        rank+= 1\n",
    "\n",
    "    if all(len(i) == len(data['Video_name']) for i in data.values()):\n",
    "        wiki_data = pd.DataFrame(data)\n",
    "        display(wiki_data)\n",
    "    else:\n",
    "        print('Arrays are not of same length')\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    print('Table not found in the webpage!')\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e714e452",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "\n",
    "You need to find following details:  \n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d2480ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open chrome and load bcci webpage\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "80fe6290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place/Venue</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024</td>\n",
       "      <td>Sylhet International Cricket Stadium, Sylhet</td>\n",
       "      <td>2 MAY, 2024</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024</td>\n",
       "      <td>Sylhet International Cricket Stadium, Sylhet</td>\n",
       "      <td>6 MAY, 2024</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024</td>\n",
       "      <td>Sylhet International Cricket Stadium, Sylhet</td>\n",
       "      <td>9 MAY, 2024</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium, N...</td>\n",
       "      <td>5 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium, N...</td>\n",
       "      <td>9 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium, N...</td>\n",
       "      <td>12 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Central Broward Park &amp; Broward County Stadium,...</td>\n",
       "      <td>15 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club, Harare</td>\n",
       "      <td>7 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Series  \\\n",
       "0  INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024   \n",
       "1  INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024   \n",
       "2  INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024   \n",
       "3                     ICC MENS T20 WORLD CUP 2024   \n",
       "4                     ICC MENS T20 WORLD CUP 2024   \n",
       "5                     ICC MENS T20 WORLD CUP 2024   \n",
       "6                     ICC MENS T20 WORLD CUP 2024   \n",
       "7                     INDIA TOUR OF ZIMBABWE 2024   \n",
       "8                     INDIA TOUR OF ZIMBABWE 2024   \n",
       "\n",
       "                                         Place/Venue           Date  \\\n",
       "0       Sylhet International Cricket Stadium, Sylhet    2 MAY, 2024   \n",
       "1       Sylhet International Cricket Stadium, Sylhet    6 MAY, 2024   \n",
       "2       Sylhet International Cricket Stadium, Sylhet    9 MAY, 2024   \n",
       "3  Nassau County International Cricket Stadium, N...   5 JUNE, 2024   \n",
       "4  Nassau County International Cricket Stadium, N...   9 JUNE, 2024   \n",
       "5  Nassau County International Cricket Stadium, N...  12 JUNE, 2024   \n",
       "6  Central Broward Park & Broward County Stadium,...  15 JUNE, 2024   \n",
       "7                         Harare Sports Club, Harare   6 JULY, 2024   \n",
       "8                         Harare Sports Club, Harare   7 JULY, 2024   \n",
       "\n",
       "          Time  \n",
       "0  3:30 PM IST  \n",
       "1  3:30 PM IST  \n",
       "2  3:30 PM IST  \n",
       "3  8:00 PM IST  \n",
       "4  8:00 PM IST  \n",
       "5  8:00 PM IST  \n",
       "6  8:00 PM IST  \n",
       "7  8:00 PM IST  \n",
       "8  8:00 PM IST  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scrape details from international fixture page\n",
    "\n",
    "try:\n",
    "    fixtures=driver.find_element(By.XPATH,'/html/body/header/div[3]/div[2]/ul/div[1]/a[2]').click()\n",
    "    time.sleep(3)\n",
    "except TimeoutException:\n",
    "    print('Timeout occured while loading the page. Refreshing again.')\n",
    "    driver.refresh()\n",
    "except NoSuchElementException:\n",
    "    print('Fixture page not found. Check if the XPath is correct.')\n",
    "    \n",
    "else:\n",
    "    ser=[]\n",
    "    plc=[]\n",
    "    dt=[]\n",
    "    tm=[]\n",
    "\n",
    "    for s in driver.find_elements(By.XPATH,'//div[@id=\"match-card\"]/div/div/div/h5'):\n",
    "        ser.append(s.text)\n",
    "    for p in driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]'):\n",
    "        combined=p.find_element(By.XPATH,'./span[1]').text + ' '+ p.find_element(By.XPATH,'./span[2]').text\n",
    "        plc.append(combined)\n",
    "\n",
    "    for d in driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]'):\n",
    "        dt.append(d.text)\n",
    "    for t in driver.find_elements(By.XPATH,'//div[@ class=\"match-time no-margin ng-binding\"]'):\n",
    "        tm.append(t.text)\n",
    "\n",
    "    if len(ser)==len(plc)==len(dt)==len(tm): \n",
    "        bcci_data=pd.DataFrame({'Series':ser,'Place/Venue':plc,'Date':dt,'Time':tm})\n",
    "        display(bcci_data)\n",
    "        \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9f6952",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "\n",
    "You have to find following details:  \n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "776920f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open chrome and load statisticstimes webpage\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "75e42754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to required page\n",
    "try:\n",
    "    econ=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button').click()\n",
    "    india=driver.find_element(By.XPATH,'//div[@class=\"dropdown-content\"]/a[3]').click()\n",
    "    time.sleep(2)\n",
    "    gdp=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()\n",
    "    time.sleep(2)\n",
    "except TimeoutException:\n",
    "    print('Timeout occured while loading the page')\n",
    "\n",
    "except NoSuchElementException:\n",
    "    print('Page not found. Check if the XPath is correct.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "195a3b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(22-23)</th>\n",
       "      <th>GSDP(21-22)</th>\n",
       "      <th>Share(21-22)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>13.17%</td>\n",
       "      <td>414.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>8.78%</td>\n",
       "      <td>276.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>2,269,995</td>\n",
       "      <td>1,978,094</td>\n",
       "      <td>8.38%</td>\n",
       "      <td>264.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>2,258,040</td>\n",
       "      <td>1,975,595</td>\n",
       "      <td>8.37%</td>\n",
       "      <td>263.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>2,230,609</td>\n",
       "      <td>1,928,683</td>\n",
       "      <td>8.17%</td>\n",
       "      <td>257.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,531,758</td>\n",
       "      <td>1,329,238</td>\n",
       "      <td>5.63%</td>\n",
       "      <td>177.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,365,849</td>\n",
       "      <td>1,193,489</td>\n",
       "      <td>5.06%</td>\n",
       "      <td>159.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1,303,524</td>\n",
       "      <td>1,148,471</td>\n",
       "      <td>4.87%</td>\n",
       "      <td>153.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,308,034</td>\n",
       "      <td>1,124,204</td>\n",
       "      <td>4.76%</td>\n",
       "      <td>150.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,246,471</td>\n",
       "      <td>1,092,964</td>\n",
       "      <td>4.63%</td>\n",
       "      <td>145.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>1,046,188</td>\n",
       "      <td>934,542</td>\n",
       "      <td>3.96%</td>\n",
       "      <td>124.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>1,014,688</td>\n",
       "      <td>881,336</td>\n",
       "      <td>3.73%</td>\n",
       "      <td>117.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>984,055</td>\n",
       "      <td>868,905</td>\n",
       "      <td>3.68%</td>\n",
       "      <td>116.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>753,177</td>\n",
       "      <td>662,886</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>88.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>751,396</td>\n",
       "      <td>650,302</td>\n",
       "      <td>2.76%</td>\n",
       "      <td>86.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>676,164</td>\n",
       "      <td>617,192</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>82.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>493,167</td>\n",
       "      <td>411,454</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>464,399</td>\n",
       "      <td>410,525</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>393,722</td>\n",
       "      <td>358,863</td>\n",
       "      <td>1.52%</td>\n",
       "      <td>47.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>303,781</td>\n",
       "      <td>267,143</td>\n",
       "      <td>1.13%</td>\n",
       "      <td>35.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>224,226</td>\n",
       "      <td>193,352</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>25.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>191,728</td>\n",
       "      <td>172,162</td>\n",
       "      <td>0.73%</td>\n",
       "      <td>22.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>93,672</td>\n",
       "      <td>84,266</td>\n",
       "      <td>0.36%</td>\n",
       "      <td>11.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>72,636</td>\n",
       "      <td>62,550</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>8.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>54,285</td>\n",
       "      <td>46,096</td>\n",
       "      <td>0.20%</td>\n",
       "      <td>6.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>49,643</td>\n",
       "      <td>43,810</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>42,697</td>\n",
       "      <td>38,785</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>42,756</td>\n",
       "      <td>37,557</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>-</td>\n",
       "      <td>36,594</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>39,630</td>\n",
       "      <td>34,775</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>35,643</td>\n",
       "      <td>31,038</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>-</td>\n",
       "      <td>27,824</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>10,371</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(22-23) GSDP(21-22) Share(21-22)  \\\n",
       "0     1                Maharashtra           -   3,108,022       13.17%   \n",
       "1     2                 Tamil Nadu   2,364,514   2,071,286        8.78%   \n",
       "2     3                  Karnataka   2,269,995   1,978,094        8.38%   \n",
       "3     4              Uttar Pradesh   2,258,040   1,975,595        8.37%   \n",
       "4     5                    Gujarat   2,230,609   1,928,683        8.17%   \n",
       "5     6                West Bengal   1,531,758   1,329,238        5.63%   \n",
       "6     7                  Rajasthan   1,365,849   1,193,489        5.06%   \n",
       "7     8             Andhra Pradesh   1,303,524   1,148,471        4.87%   \n",
       "8     9                  Telangana   1,308,034   1,124,204        4.76%   \n",
       "9    10             Madhya Pradesh   1,246,471   1,092,964        4.63%   \n",
       "10   11                     Kerala   1,046,188     934,542        3.96%   \n",
       "11   12                      Delhi   1,014,688     881,336        3.73%   \n",
       "12   13                    Haryana     984,055     868,905        3.68%   \n",
       "13   14                     Odisha     753,177     662,886        2.81%   \n",
       "14   15                      Bihar     751,396     650,302        2.76%   \n",
       "15   16                     Punjab     676,164     617,192        2.62%   \n",
       "16   17                      Assam     493,167     411,454        1.74%   \n",
       "17   18               Chhattisgarh     464,399     410,525        1.74%   \n",
       "18   19                  Jharkhand     393,722     358,863        1.52%   \n",
       "19   20                Uttarakhand     303,781     267,143        1.13%   \n",
       "20   21            Jammu & Kashmir     224,226     193,352        0.82%   \n",
       "21   22           Himachal Pradesh     191,728     172,162        0.73%   \n",
       "22   23                        Goa      93,672      84,266        0.36%   \n",
       "23   24                    Tripura      72,636      62,550        0.27%   \n",
       "24   25                 Chandigarh      54,285      46,096        0.20%   \n",
       "25   26                 Puducherry      49,643      43,810        0.19%   \n",
       "26   27                  Meghalaya      42,697      38,785        0.16%   \n",
       "27   28                     Sikkim      42,756      37,557        0.16%   \n",
       "28   29                    Manipur           -      36,594        0.16%   \n",
       "29   30          Arunachal Pradesh      39,630      34,775        0.15%   \n",
       "30   31                   Nagaland      35,643      31,038        0.13%   \n",
       "31   32                    Mizoram           -      27,824        0.12%   \n",
       "32   33  Andaman & Nicobar Islands           -      10,371        0.04%   \n",
       "\n",
       "   GDP($ billion)  \n",
       "0         414.928  \n",
       "1         276.522  \n",
       "2         264.080  \n",
       "3         263.747  \n",
       "4         257.484  \n",
       "5         177.456  \n",
       "6         159.334  \n",
       "7         153.324  \n",
       "8         150.084  \n",
       "9         145.913  \n",
       "10        124.764  \n",
       "11        117.660  \n",
       "12        116.001  \n",
       "13         88.497  \n",
       "14         86.817  \n",
       "15         82.397  \n",
       "16         54.930  \n",
       "17         54.806  \n",
       "18         47.909  \n",
       "19         35.664  \n",
       "20         25.813  \n",
       "21         22.984  \n",
       "22         11.250  \n",
       "23          8.351  \n",
       "24          6.154  \n",
       "25          5.849  \n",
       "26          5.178  \n",
       "27          5.014  \n",
       "28          4.885  \n",
       "29          4.643  \n",
       "30          4.144  \n",
       "31          3.715  \n",
       "32          1.385  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scrape data\n",
    "\n",
    "rank=[]\n",
    "state=[]\n",
    "g1=[]\n",
    "g2=[]\n",
    "s1=[]\n",
    "gdp=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    for r in driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[1]'):\n",
    "        rank.append(r.text)\n",
    "\n",
    "    for s in driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[2]'):\n",
    "        state.append(s.text)\n",
    "\n",
    "    for gsdp1 in driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[4]'):\n",
    "            g1.append(gsdp1.text)\n",
    "\n",
    "    for gsdp2 in driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[5]'):\n",
    "        g2.append(gsdp2.text)\n",
    "\n",
    "    for share in driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[6]'):\n",
    "        s1.append(share.text)\n",
    "\n",
    "    for g in driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[7]'):\n",
    "        gdp.append(g.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    rank.append('-')\n",
    "    state.append('-')\n",
    "    g1.append('-')\n",
    "    g2.append('-')\n",
    "    s1.append('-')\n",
    "    gdp.append('-')\n",
    "    \n",
    "if len(rank)==len(state)==len(g1)==len(g2)==len(s1)==len(gdp):\n",
    "    india_stats=pd.DataFrame({'Rank':rank,'State':state,'GSDP(22-23)': g1, 'GSDP(21-22)':g2,'Share(21-22)':s1,'GDP($ billion)':gdp})\n",
    "    display(india_stats)\n",
    "else:\n",
    "    print('Arrays are not of same length')\n",
    "    print('Lengths of arrays are: \\n Rank: ',len(rank),'\\n State: ',len(state),'\\n GSDP1: ',len(g1),'\\n GSDP2: ',len(g2),'\\n Share: ',len(s1),'\\n GDP: ',len(gdp))\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a622ab",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4915a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open chrome and load github webpage\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d843f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signin to access\n",
    "\n",
    "signin=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/div/div/a').click()\n",
    "time.sleep(2)\n",
    "enter_uid=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/main/div/div[4]/form/input[2]').send_keys('dummysample098@gmail.com')\n",
    "enter_pw=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/main/div/div[4]/form/div/input[1]').send_keys('dummysample852#')\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/main/div/div[4]/form/div/input[13]').click()\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "094b9f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to trendings section\n",
    "explore=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div/div/div/aside/div[3]/div/a').click()\n",
    "time.sleep(3)\n",
    "trending=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/main/div[1]/nav/div/a[3]').click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9804471d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of list: 25 \n",
      " ['https://github.com/dnhkng/GlaDOS', 'https://github.com/TheOfficialFloW/PPPwn', 'https://github.com/freeCodeCamp/freeCodeCamp', 'https://github.com/fastfetch-cli/fastfetch', 'https://github.com/hydralauncher/hydra', 'https://github.com/TracecatHQ/tracecat', 'https://github.com/coollabsio/coolify', 'https://github.com/dylanaraps/neofetch', 'https://github.com/ItzCrazyKns/Perplexica', 'https://github.com/Orange-OpenSource/hurl', 'https://github.com/pagefaultgames/pokerogue', 'https://github.com/penpot/penpot', 'https://github.com/yangshun/tech-interview-handbook', 'https://github.com/Dokploy/dokploy', 'https://github.com/codecrafters-io/build-your-own-x', 'https://github.com/xlang-ai/OSWorld', 'https://github.com/NaiboWang/EasySpider', 'https://github.com/trimstray/the-book-of-secret-knowledge', 'https://github.com/pytorch/executorch', 'https://github.com/kelseyhightower/kubernetes-the-hard-way', 'https://github.com/MagicMirrorOrg/MagicMirror', 'https://github.com/aptos-labs/aptos-core', 'https://github.com/idk10-a/aviator', 'https://github.com/FRRouting/frr', 'https://github.com/mdn/content']\n"
     ]
    }
   ],
   "source": [
    "# scrape links of each repositories\n",
    "\n",
    "links=[]\n",
    "try:\n",
    "    for link in driver.find_elements(By.XPATH,'//a[@class=\"Link\"]'):\n",
    "        links.append(link.get_attribute('href'))\n",
    "    print('Length of list:', len(links), '\\n',links)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    print(\"Specified element not found\")\n",
    "    \n",
    "except StaleElementReferenceException:\n",
    "    print(\"Referenced element is no longer attached to the DOM\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4b8adc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trending repository</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GlaDOS</td>\n",
       "      <td>Personality Core</td>\n",
       "      <td>4</td>\n",
       "      <td>Python , Jupyter Notebook ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PPPwn</td>\n",
       "      <td>PPPwn - PlayStation 4 PPPoE RCE</td>\n",
       "      <td>8</td>\n",
       "      <td>Python , C , Makefile , Assembly , Other ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>freeCodeCamp</td>\n",
       "      <td>freeCodeCamp.org's open-source codebase and cu...</td>\n",
       "      <td>5,000+</td>\n",
       "      <td>TypeScript , JavaScript , CSS , Dockerfile , E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fastfetch</td>\n",
       "      <td>Like neofetch, but much faster because written...</td>\n",
       "      <td>84</td>\n",
       "      <td>C , C++ , Objective-C , CMake , Shell ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hydra</td>\n",
       "      <td>Hydra is a game launcher with its own embedded...</td>\n",
       "      <td>13</td>\n",
       "      <td>TypeScript , Python , Other ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tracecat</td>\n",
       "      <td>😼 The open source alternative to Tines / Splun...</td>\n",
       "      <td>3</td>\n",
       "      <td>TypeScript , Python , Other ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>coolify</td>\n",
       "      <td>An open-source &amp; self-hostable Heroku / Netlif...</td>\n",
       "      <td>114</td>\n",
       "      <td>PHP , Blade , Vue , Shell , Dockerfile , CSS ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neofetch</td>\n",
       "      <td>🖼️ A command-line system information tool writ...</td>\n",
       "      <td>207</td>\n",
       "      <td>Shell , Roff , Makefile ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Perplexica</td>\n",
       "      <td>Perplexica is an AI-powered search engine. It ...</td>\n",
       "      <td>2</td>\n",
       "      <td>TypeScript , Other ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hurl</td>\n",
       "      <td>Hurl, run and test HTTP requests with plain text.</td>\n",
       "      <td>54</td>\n",
       "      <td>Rust , Python , Shell , PowerShell , HTML , Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pokerogue</td>\n",
       "      <td>-</td>\n",
       "      <td>76</td>\n",
       "      <td>TypeScript , PowerShell , PLSQL , JavaScript ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>penpot</td>\n",
       "      <td>Penpot: The open-source design tool for design...</td>\n",
       "      <td>152</td>\n",
       "      <td>Clojure , JavaScript , SCSS , HTML , Shell , J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tech-interview-handbook</td>\n",
       "      <td>💯 Curated coding interview preparation materia...</td>\n",
       "      <td>157</td>\n",
       "      <td>TypeScript , JavaScript , Python , Other ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dokploy</td>\n",
       "      <td>Open Source Alternative to Vercel, Netlify and...</td>\n",
       "      <td>8</td>\n",
       "      <td>TypeScript , Other ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>build-your-own-x</td>\n",
       "      <td>Master programming by recreating your favorite...</td>\n",
       "      <td>116</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>OSWorld</td>\n",
       "      <td>OSWorld: Benchmarking Multimodal Agents for Op...</td>\n",
       "      <td>15</td>\n",
       "      <td>Python , JavaScript ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>EasySpider</td>\n",
       "      <td>A visual no-code/code-free web crawler/spider易...</td>\n",
       "      <td>6</td>\n",
       "      <td>JavaScript , Python , HTML , CSS , Vue , Batch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>the-book-of-secret-knowledge</td>\n",
       "      <td>A collection of inspiring lists, manuals, chea...</td>\n",
       "      <td>100</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>executorch</td>\n",
       "      <td>On-device AI across mobile, embedded and edge ...</td>\n",
       "      <td>94</td>\n",
       "      <td>C++ , Python , Objective-C++ , Starlark , CMak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kubernetes-the-hard-way</td>\n",
       "      <td>Bootstrap Kubernetes the hard way. No scripts.</td>\n",
       "      <td>52</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MagicMirror</td>\n",
       "      <td>MagicMirror² is an open source modular smart m...</td>\n",
       "      <td>328</td>\n",
       "      <td>JavaScript , CSS , Nunjucks , Other ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>aptos-core</td>\n",
       "      <td>Aptos is a layer 1 blockchain built to support...</td>\n",
       "      <td>497</td>\n",
       "      <td>Rust , Move , TypeScript , Python , HCL , Shel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aviator</td>\n",
       "      <td>Level up your Aviator game! This bot employs i...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>frr</td>\n",
       "      <td>The FRRouting Protocol Suite</td>\n",
       "      <td>412</td>\n",
       "      <td>C , Python , Perl , M4 , C++ , Shell , Other ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>content</td>\n",
       "      <td>The content behind MDN Web Docs</td>\n",
       "      <td>4,275</td>\n",
       "      <td>Markdown , Other ,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Trending repository  \\\n",
       "0                         GlaDOS   \n",
       "1                          PPPwn   \n",
       "2                   freeCodeCamp   \n",
       "3                      fastfetch   \n",
       "4                          hydra   \n",
       "5                       tracecat   \n",
       "6                        coolify   \n",
       "7                       neofetch   \n",
       "8                     Perplexica   \n",
       "9                           hurl   \n",
       "10                     pokerogue   \n",
       "11                        penpot   \n",
       "12       tech-interview-handbook   \n",
       "13                       dokploy   \n",
       "14              build-your-own-x   \n",
       "15                       OSWorld   \n",
       "16                    EasySpider   \n",
       "17  the-book-of-secret-knowledge   \n",
       "18                    executorch   \n",
       "19       kubernetes-the-hard-way   \n",
       "20                   MagicMirror   \n",
       "21                    aptos-core   \n",
       "22                       aviator   \n",
       "23                           frr   \n",
       "24                       content   \n",
       "\n",
       "                                          Description Contributors count  \\\n",
       "0                                    Personality Core                  4   \n",
       "1                     PPPwn - PlayStation 4 PPPoE RCE                  8   \n",
       "2   freeCodeCamp.org's open-source codebase and cu...             5,000+   \n",
       "3   Like neofetch, but much faster because written...                 84   \n",
       "4   Hydra is a game launcher with its own embedded...                 13   \n",
       "5   😼 The open source alternative to Tines / Splun...                  3   \n",
       "6   An open-source & self-hostable Heroku / Netlif...                114   \n",
       "7   🖼️ A command-line system information tool writ...                207   \n",
       "8   Perplexica is an AI-powered search engine. It ...                  2   \n",
       "9   Hurl, run and test HTTP requests with plain text.                 54   \n",
       "10                                                  -                 76   \n",
       "11  Penpot: The open-source design tool for design...                152   \n",
       "12  💯 Curated coding interview preparation materia...                157   \n",
       "13  Open Source Alternative to Vercel, Netlify and...                  8   \n",
       "14  Master programming by recreating your favorite...                116   \n",
       "15  OSWorld: Benchmarking Multimodal Agents for Op...                 15   \n",
       "16  A visual no-code/code-free web crawler/spider易...                  6   \n",
       "17  A collection of inspiring lists, manuals, chea...                100   \n",
       "18  On-device AI across mobile, embedded and edge ...                 94   \n",
       "19     Bootstrap Kubernetes the hard way. No scripts.                 52   \n",
       "20  MagicMirror² is an open source modular smart m...                328   \n",
       "21  Aptos is a layer 1 blockchain built to support...                497   \n",
       "22  Level up your Aviator game! This bot employs i...                  -   \n",
       "23                       The FRRouting Protocol Suite                412   \n",
       "24                    The content behind MDN Web Docs              4,275   \n",
       "\n",
       "                                        Language used  \n",
       "0                         Python , Jupyter Notebook ,  \n",
       "1          Python , C , Makefile , Assembly , Other ,  \n",
       "2   TypeScript , JavaScript , CSS , Dockerfile , E...  \n",
       "3             C , C++ , Objective-C , CMake , Shell ,  \n",
       "4                       TypeScript , Python , Other ,  \n",
       "5                       TypeScript , Python , Other ,  \n",
       "6   PHP , Blade , Vue , Shell , Dockerfile , CSS ,...  \n",
       "7                           Shell , Roff , Makefile ,  \n",
       "8                                TypeScript , Other ,  \n",
       "9   Rust , Python , Shell , PowerShell , HTML , Ro...  \n",
       "10  TypeScript , PowerShell , PLSQL , JavaScript ,...  \n",
       "11  Clojure , JavaScript , SCSS , HTML , Shell , J...  \n",
       "12         TypeScript , JavaScript , Python , Other ,  \n",
       "13                               TypeScript , Other ,  \n",
       "14                                                  -  \n",
       "15                              Python , JavaScript ,  \n",
       "16  JavaScript , Python , HTML , CSS , Vue , Batch...  \n",
       "17                                                  -  \n",
       "18  C++ , Python , Objective-C++ , Starlark , CMak...  \n",
       "19                                                  -  \n",
       "20              JavaScript , CSS , Nunjucks , Other ,  \n",
       "21  Rust , Move , TypeScript , Python , HCL , Shel...  \n",
       "22                                                  -  \n",
       "23     C , Python , Perl , M4 , C++ , Shell , Other ,  \n",
       "24                                 Markdown , Other ,  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scrape data\n",
    "\n",
    "titles=[]\n",
    "desc=[]\n",
    "count=[]\n",
    "lang=[]\n",
    "\n",
    "for i in links:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "       \n",
    "    for title in driver.find_elements(By.XPATH,'//strong[@class=\"mr-2 flex-self-stretch d-none d-md-block\"]'):\n",
    "        if title:\n",
    "            titles.append(title.text)\n",
    "        else:\n",
    "            titles.append('-')\n",
    "        \n",
    "    data_present=False\n",
    "    for de in driver.find_elements(By.XPATH,'//div[@class=\"BorderGrid-cell\"]/div/p'):\n",
    "        desc.append(de.text)\n",
    "        data_present=True\n",
    "    if not data_present:\n",
    "        desc.append('-')\n",
    "    \n",
    "    data_present=False\n",
    "    for ct in driver.find_elements(By.XPATH,'//*[contains(text(), \"Contributors\")]/span'):\n",
    "        count.append(ct.text)\n",
    "        data_present = True\n",
    "    \n",
    "    if not data_present:\n",
    "        count.append('-')\n",
    "        \n",
    "    data_present=False    \n",
    "    for la in driver.find_elements(By.XPATH,'//div[contains(., \"Languages\")]/ul'):\n",
    "        text=la.text\n",
    "        replaced=text.replace('\\n',' ')\n",
    "        pattern=re.compile(r'\\d+.\\d+\\%')\n",
    "        edited_text=pattern.sub(',',replaced)\n",
    "        lang.append(edited_text)\n",
    "        data_present=True\n",
    "    if not data_present:\n",
    "        lang.append('-')\n",
    "\n",
    "if len(titles)==len(desc)==len(count)==len(lang):\n",
    "    github_data=pd.DataFrame({'Trending repository': titles,'Description':desc,'Contributors count':count,'Language used':lang})\n",
    "    display(github_data)\n",
    "else:\n",
    "    print('Arrays are not of same length\\n')\n",
    "    print('Lengths of arrays are: \\n Titles: ',len(titles),'\\n Description: ',len(desc),'\\n Count: ',len(count),'\\n Language: ',len(lang))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5558396",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958eaba3",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of top 100 songs on billiboard.com. \n",
    "Url = https:/www.billboard.com/ \n",
    "\n",
    "You have to find the following details:  \n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34494340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Week on Chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fortnight</td>\n",
       "      <td>Taylor Swift Featuring Post Malone</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Down Bad</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I Can Do It With A Broken Heart</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Tortured Poets Department</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So Long, London</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Us Vs. Them</td>\n",
       "      <td>$uicideBoy$</td>\n",
       "      <td>-</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Wine Into Whiskey</td>\n",
       "      <td>Tucker Wetmore</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Spin You Around (1/24)</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>89</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Soak City</td>\n",
       "      <td>310babii</td>\n",
       "      <td>82</td>\n",
       "      <td>53</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Selfish</td>\n",
       "      <td>Justin Timberlake</td>\n",
       "      <td>60</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Song                              Artist  \\\n",
       "0                         Fortnight  Taylor Swift Featuring Post Malone   \n",
       "1                          Down Bad                        Taylor Swift   \n",
       "2   I Can Do It With A Broken Heart                        Taylor Swift   \n",
       "3     The Tortured Poets Department                        Taylor Swift   \n",
       "4                   So Long, London                        Taylor Swift   \n",
       "..                              ...                                 ...   \n",
       "95                      Us Vs. Them                         $uicideBoy$   \n",
       "96                Wine Into Whiskey                      Tucker Wetmore   \n",
       "97           Spin You Around (1/24)                       Morgan Wallen   \n",
       "98                        Soak City                            310babii   \n",
       "99                          Selfish                   Justin Timberlake   \n",
       "\n",
       "   Last week Rank Peak Rank Week on Chart  \n",
       "0               -         1             1  \n",
       "1               -         2             1  \n",
       "2               -         3             1  \n",
       "3               -         4             1  \n",
       "4               -         5             1  \n",
       "..            ...       ...           ...  \n",
       "95              -        96             1  \n",
       "96             84        77             5  \n",
       "97             89        24            13  \n",
       "98             82        53            19  \n",
       "99             60        19            13  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# open chrome and load billboard webpage\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('http://www.billboard.com/')\n",
    "\n",
    "# navigate to hot 100-page link\n",
    "charts=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a').click()\n",
    "time.sleep(3)\n",
    "hot=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[3]/div/nav/ul/li[1]/a').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# scrape data\n",
    "data=[]\n",
    "try:\n",
    "    for d in driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]'):\n",
    "        data.append(d.text.split('\\n'))\n",
    "    \n",
    "    # split data to separate lists and make a dataframe\n",
    "    song=[item[0] for item in data]\n",
    "    artist=[item[1] for item in data]\n",
    "    lwr=[item[2] for item in data]\n",
    "    pr=[item[3] for item in data]\n",
    "    wob=[item[4] for item in data]\n",
    "    top100_music=pd.DataFrame({'Song':song,'Artist':artist,'Last week Rank':lwr,'Peak Rank':pr,'Week on Chart':wob})\n",
    "    display(top100_music)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'Error occured {e}')\n",
    "    \n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217cab43",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of Highest selling novels.\n",
    "\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    "\n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86e2ad38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Book            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# open chrome and load theguardian webpage\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')\n",
    "time.sleep(2)\n",
    "\n",
    "# scrape data\n",
    "\n",
    "data=[]\n",
    "try:\n",
    "    table=driver.find_element(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody') \n",
    "    rows=table.find_elements(By.TAG_NAME,'tr')\n",
    "    for row in rows:\n",
    "        records=row.find_elements(By.TAG_NAME,'td')\n",
    "        data.append([record.text for record in records])\n",
    "            \n",
    "    novels_data=pd.DataFrame(data,columns=['Rank','Book','Author','Volumes Sold','Publisher','Genre'])\n",
    "    display(novels_data.drop(columns=['Rank']))\n",
    "    \n",
    "except NoSuchElementException:\n",
    "    print('Table not found / Element not found in the table')\n",
    "except Exception as e:\n",
    "    print(f'Error occured: {e}')\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1448d5e",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls512407256/ \n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ebed7109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>60 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,285,808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,337,079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>45 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,082,551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>315,629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>276,243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>True Detective</td>\n",
       "      <td>(2014– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>656,832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Teen Wolf</td>\n",
       "      <td>(2011–2017)</td>\n",
       "      <td>Action, Drama, Fantasy</td>\n",
       "      <td>41 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>163,314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The OA</td>\n",
       "      <td>(2016–2019)</td>\n",
       "      <td>Drama, Fantasy, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>115,914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Simpsons</td>\n",
       "      <td>(1989– )</td>\n",
       "      <td>Animation, Comedy</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>436,059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Desperate Housewives</td>\n",
       "      <td>(2004–2012)</td>\n",
       "      <td>Comedy, Drama, Mystery</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>139,811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Series Name    Year Span                     Genre Run Time  \\\n",
       "0        Game of Thrones  (2011–2019)  Action, Adventure, Drama   60 min   \n",
       "1        Stranger Things  (2016–2025)    Drama, Fantasy, Horror   60 min   \n",
       "2       The Walking Dead  (2010–2022)   Drama, Horror, Thriller   45 min   \n",
       "3         13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   60 min   \n",
       "4                The 100  (2014–2020)    Drama, Mystery, Sci-Fi   43 min   \n",
       "..                   ...          ...                       ...      ...   \n",
       "95        True Detective     (2014– )     Crime, Drama, Mystery   60 min   \n",
       "96             Teen Wolf  (2011–2017)    Action, Drama, Fantasy   41 min   \n",
       "97                The OA  (2016–2019)   Drama, Fantasy, Mystery   60 min   \n",
       "98          The Simpsons     (1989– )         Animation, Comedy   22 min   \n",
       "99  Desperate Housewives  (2004–2012)    Comedy, Drama, Mystery   45 min   \n",
       "\n",
       "   Rating      Votes  \n",
       "0     9.2  2,285,808  \n",
       "1     8.7  1,337,079  \n",
       "2     8.1  1,082,551  \n",
       "3     7.5    315,629  \n",
       "4     7.6    276,243  \n",
       "..    ...        ...  \n",
       "95    8.9    656,832  \n",
       "96    7.7    163,314  \n",
       "97    7.8    115,914  \n",
       "98    8.7    436,059  \n",
       "99    7.6    139,811  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# open chrome and load imdb webpage\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.imdb.com/list/ls512407256/')\n",
    "time.sleep(2)\n",
    "\n",
    "# scrape data\n",
    "\n",
    "name=[]\n",
    "yr=[]\n",
    "gnr=[]\n",
    "runtm=[]\n",
    "rate=[]\n",
    "vt=[]\n",
    "\n",
    "try:\n",
    "    for n in driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a'):\n",
    "        name.append(n.text)\n",
    "    for y in driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/span[2]'):\n",
    "        yr.append(y.text)\n",
    "    for g in driver.find_elements(By.XPATH,'//span[@class=\"genre\"]'):\n",
    "        gnr.append(g.text)    \n",
    "    for rt in driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]'):\n",
    "        runtm.append(rt.text)\n",
    "    for r in driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-widget\"]/div/span[2]'):\n",
    "        rate.append(r.text)\n",
    "    for v in driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p[4]/span[2]'):\n",
    "        vt.append(v.text)\n",
    "\n",
    "    if len(name)==len(yr)==len(gnr)==len(runtm)==len(rate)==len(vt):\n",
    "        imdb_data=pd.DataFrame({'Series Name':name,'Year Span':yr,'Genre':gnr,'Run Time':runtm,'Rating':rate,'Votes':vt})\n",
    "        display(imdb_data)\n",
    "    else:\n",
    "    print('Arrays are not of same length\\n')\n",
    "    print('Lengths of arrays are: \\n Series Name: ',len(name),'\\n Year Span: ',len(yr),'\\n Genre: ',len(gnr),'\\n Run Time: ',len(runtm),'\\n Rating: ',len(rate),'\\n Votes: ',len(vt))\n",
    "        \n",
    "except Exceptions as e:\n",
    "    print(f'Error occured: ', e)\n",
    "    \n",
    "driver.quit()    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4427df08",
   "metadata": {},
   "source": [
    "# 8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/  \n",
    "You have to find the following details:  \n",
    "\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute \n",
    "G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "650a5216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open chrome and load uci webpage\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://archive.ics.uci.edu/')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0c0b1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to show all datasets\n",
    "\n",
    "try:\n",
    "    showall = driver.find_element(By.XPATH,'//a[@class=\"btn-ghost btn mb-2 text-center text-primary hover:underline\"]').click()\n",
    "except ElementClickInterceptedException:    \n",
    "    action = ActionChains(driver)\n",
    "    showall = driver.find_element(By.XPATH,'//a[@ class=\"btn-ghost btn mb-2 text-center text-primary hover:underline\"]')\n",
    "    action.move_to_element(showall).perform()\n",
    "    showall.click()\n",
    "time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5e98e53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of list: 10 \n",
      " ['https://archive.ics.uci.edu/dataset/53/iris', 'https://archive.ics.uci.edu/dataset/45/heart+disease', 'https://archive.ics.uci.edu/dataset/602/dry+bean+dataset', 'https://archive.ics.uci.edu/dataset/545/rice+cammeo+and+osmancik', 'https://archive.ics.uci.edu/dataset/2/adult']\n"
     ]
    }
   ],
   "source": [
    "# scrape individual links\n",
    "\n",
    "links=[]\n",
    "try:\n",
    "    for link in driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]/h2/a'):\n",
    "        links.append(link.get_attribute('href'))\n",
    "    print('Length of list:', len(links), '\\n',links[:5])\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    print(\"Specified element not found\")\n",
    "    \n",
    "except StaleElementReferenceException:\n",
    "    print(\"Referenced element is no longer attached to the DOM\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eaef82c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Datatype</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No. of Instances</th>\n",
       "      <th>Attribute Number</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PhiUSIIL Phishing URL (Website)</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real, Categorical, Integer</td>\n",
       "      <td>235795</td>\n",
       "      <td>54</td>\n",
       "      <td>[2024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT-IoT2022</td>\n",
       "      <td>Tabular, Sequential, Multivariate</td>\n",
       "      <td>Classification, Regression, Clustering</td>\n",
       "      <td>Real, Categorical</td>\n",
       "      <td>123117</td>\n",
       "      <td>83</td>\n",
       "      <td>[2024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regensburg Pediatric Appendicitis</td>\n",
       "      <td>Tabular, Image</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real, Categorical, Integer</td>\n",
       "      <td>782</td>\n",
       "      <td>53</td>\n",
       "      <td>[2023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>National Poll on Healthy Aging (NPHA)</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>714</td>\n",
       "      <td>14</td>\n",
       "      <td>[2023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Infrared Thermography Temperature</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real, Categorical</td>\n",
       "      <td>1020</td>\n",
       "      <td>33</td>\n",
       "      <td>[2023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jute Pest</td>\n",
       "      <td>Image</td>\n",
       "      <td>Classification, Other</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>7235</td>\n",
       "      <td>17</td>\n",
       "      <td>[2023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Differentiated Thyroid Cancer Recurrence</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real, Categorical, Integer</td>\n",
       "      <td>383</td>\n",
       "      <td>16</td>\n",
       "      <td>[2023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Forty Soybean Cultivars from Subsequent Harvests</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification, Regression, Clustering, Other</td>\n",
       "      <td>Real, Categorical, Integer</td>\n",
       "      <td>320</td>\n",
       "      <td>11</td>\n",
       "      <td>[2023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Recipe Reviews and User Feedback</td>\n",
       "      <td>Tabular, Other</td>\n",
       "      <td>Classification, Other</td>\n",
       "      <td>Real, Categorical, Integer</td>\n",
       "      <td>18182</td>\n",
       "      <td>15</td>\n",
       "      <td>[2023]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RealWaste</td>\n",
       "      <td>Image</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>4752</td>\n",
       "      <td>-</td>\n",
       "      <td>[2023]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Dataset  \\\n",
       "0                   PhiUSIIL Phishing URL (Website)   \n",
       "1                                        RT-IoT2022   \n",
       "2                 Regensburg Pediatric Appendicitis   \n",
       "3             National Poll on Healthy Aging (NPHA)   \n",
       "4                 Infrared Thermography Temperature   \n",
       "5                                         Jute Pest   \n",
       "6          Differentiated Thyroid Cancer Recurrence   \n",
       "7  Forty Soybean Cultivars from Subsequent Harvests   \n",
       "8                  Recipe Reviews and User Feedback   \n",
       "9                                         RealWaste   \n",
       "\n",
       "                            Datatype  \\\n",
       "0                            Tabular   \n",
       "1  Tabular, Sequential, Multivariate   \n",
       "2                     Tabular, Image   \n",
       "3                            Tabular   \n",
       "4                            Tabular   \n",
       "5                              Image   \n",
       "6                            Tabular   \n",
       "7                            Tabular   \n",
       "8                     Tabular, Other   \n",
       "9                              Image   \n",
       "\n",
       "                                            Task              Attribute Type  \\\n",
       "0                                 Classification  Real, Categorical, Integer   \n",
       "1         Classification, Regression, Clustering           Real, Categorical   \n",
       "2                                 Classification  Real, Categorical, Integer   \n",
       "3                                 Classification                 Categorical   \n",
       "4                                     Regression           Real, Categorical   \n",
       "5                          Classification, Other                 Categorical   \n",
       "6                                 Classification  Real, Categorical, Integer   \n",
       "7  Classification, Regression, Clustering, Other  Real, Categorical, Integer   \n",
       "8                          Classification, Other  Real, Categorical, Integer   \n",
       "9                                 Classification                           -   \n",
       "\n",
       "  No. of Instances Attribute Number    Year  \n",
       "0           235795               54  [2024]  \n",
       "1           123117               83  [2024]  \n",
       "2              782               53  [2023]  \n",
       "3              714               14  [2023]  \n",
       "4             1020               33  [2023]  \n",
       "5             7235               17  [2023]  \n",
       "6              383               16  [2023]  \n",
       "7              320               11  [2023]  \n",
       "8            18182               15  [2023]  \n",
       "9             4752                -  [2023]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scrape data\n",
    "\n",
    "dtst=[]\n",
    "dtype=[]\n",
    "task=[]\n",
    "attp=[]\n",
    "inst=[]\n",
    "atno=[]\n",
    "year=[]\n",
    "\n",
    "try:\n",
    "    for i in links:\n",
    "        driver.get(i)\n",
    "        time.sleep(2)\n",
    "\n",
    "        for ds in driver.find_elements(By.XPATH,'//div[@class=\"relative flex flex w-full items-center gap-4 bg-primary p-2\"]/div[2]/div/h1'):\n",
    "            dtst.append(ds.text)\n",
    "        for dt in driver.find_elements(By.XPATH,'//div[@class=\"relative flex flex-col gap-4 bg-base-100 p-4 shadow\"]/div[2]/div[1]/p'):\n",
    "            dtype.append(dt.text)\n",
    "        for t in driver.find_elements(By.XPATH,'//div[@class=\"relative flex flex-col gap-4 bg-base-100 p-4 shadow\"]/div[2]/div[3]/p'):\n",
    "            task.append(t.text)\n",
    "        for at in driver.find_elements(By.XPATH,'//div[@class=\"relative flex flex-col gap-4 bg-base-100 p-4 shadow\"]/div[2]/div[4]/p'):\n",
    "            attp.append(at.text)\n",
    "        for ins in  driver.find_elements(By.XPATH,'//div[@class=\"relative flex flex-col gap-4 bg-base-100 p-4 shadow\"]/div[2]/div[5]/p'):\n",
    "            inst.append(ins.text)\n",
    "        for an in driver.find_elements(By.XPATH,'//div[@class=\"relative flex flex-col gap-4 bg-base-100 p-4 shadow\"]/div[2]/div[6]/p'):\n",
    "            atno.append(an.text)\n",
    "        for yr in driver.find_elements(By.XPATH,'//div[@class=\"relative flex flex w-full items-center gap-4 bg-primary p-2\"]/div[2]/h2'):\n",
    "            yr_text=yr.text\n",
    "            extracted_year=re.findall(r'\\d{4}',yr_text)\n",
    "            year.append(extracted_year)\n",
    "            \n",
    "    if len(dtst)==len(dtype)==len(task)==len(attp)==len(inst)==len(atno)==len(year):\n",
    "        dataset_data=pd.DataFrame({'Dataset':dtst,'Datatype':dtype,'Task':task,'Attribute Type':attp,'No. of Instances':inst,'Attribute Number':atno,'Year':year})\n",
    "        display(dataset_data)\n",
    "    else:\n",
    "        print('Arrays are not of same length\\n')\n",
    "        print('Lengths of arrays are: \\n Dataset: ',len(dtst),'\\n Datatype: ',len(dtype),'\\n Task: ',len(task))\n",
    "            \n",
    "except NoSuchElementException:\n",
    "    dtst.append('-')\n",
    "    dtype.append('-')\n",
    "    task.append('-')\n",
    "    attp.append('-')\n",
    "    inst.append('-')\n",
    "    atno.append('-')\n",
    "    year.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1f20effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbdc2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
